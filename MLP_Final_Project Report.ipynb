{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e6da64",
   "metadata": {},
   "source": [
    "# Real-Estate House Price Prediction\n",
    "\n",
    "#### Jay Patel (200538083), 200538083@student.georgianc.on.ca\n",
    "\n",
    "#### Deven Modi (200539304), 200539304@student.georgianc.on.ca\n",
    "\n",
    "### Machine Learning Programming - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854284d-a79c-4674-8f09-05a68aebf557",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b41fc-883e-41ce-be3e-9e27e14459ea",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project is centered around the development and application of a novel method known as Geo-Spatial Network Embedding (GSNE) for predicting house prices. The GSNE technique leverages the power of graph neural networks to capture the geo-spatial context of a neighborhood, thereby addressing the limitations of existing real estate price prediction models. These traditional models often overlook the influence of neighborhood amenities on house prices, such as proximity to a train station, a highly-ranked school, or a shopping center. By incorporating these factors, the GSNE method provides a more comprehensive and accurate approach to predicting house prices.\n",
    "\n",
    "The GSNE method represents houses and various types of Points of Interest (POIs) as attributed nodes in multipartite networks, with the relationships between them represented as edges. This allows for the learning of embeddings of houses and POIs, which are then used to improve the performance of the house price prediction task. Extensive experiments have shown that the embeddings produced by the GSNE technique consistently enhance the accuracy of house price predictions, regardless of the downstream regression model used. Through this innovative approach, the project aims to benefit various stakeholders in the real estate market by providing a more context-aware method for predicting house prices.s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c07fc8-8c66-433b-8ae0-bdf6d15c9d3a",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "The project addresses a key problem in real estate price prediction: the lack of consideration for the geo-spatial context of neighborhood amenities in existing models. Traditional models often overlook factors such as proximity to a train station, a highly-ranked school, or a shopping center, which can significantly influence a house's price. This project proposes a novel method, the Geo-Spatial Network Embedding (GSNE), which leverages graph neural networks to capture this geo-spatial context, thereby aiming to enhance the accuracy of house price predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544492a-28a6-4010-a455-4246b0035dc9",
   "metadata": {},
   "source": [
    "## Context of the Problem\n",
    "\n",
    "The context of the problem lies in the field of real estate price prediction. Real estate significantly contributes to all major economies around the world, and house prices have a direct impact on stakeholders, ranging from house buyers to financing companies. A variety of techniques have been developed for real estate price prediction, most of which rely on different house features to build a variety of prediction models. Some later works introduced spatial regression models to improve prediction performance, recognizing the effect of spatial dependence on house prices. However, these models often fail to consider the geo-spatial context of neighborhood amenities, such as how close a house is to a train station, a highly-ranked school, or a shopping center. Such contextual information can significantly influence a user’s interest in a house and thereby its price. This lack of contextual information in current models is the key problem that this project aims to address.89-x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bc546-d7bd-426e-9446-df57aca838fc",
   "metadata": {},
   "source": [
    "## Limitation about approach\n",
    "\n",
    "Traditional real estate price prediction models have several limitations. Most of these models rely heavily on house features to predict prices, such as the size of the house, the number of rooms, the age of the house, and so on. While these features are undoubtedly important, they do not provide a complete picture of what drives house prices.\r\n",
    "\r\n",
    "One significant limitation is that these models often overlook the effect of spatial dependence on house prices. Some later works introduced spatial regression models to improve prediction performance, recognizing this effect. However, even these models fail to consider the geo-spatial context of neighborhood amenities. For example, the proximity of a house to a train station, a highly-ranked school, or a shopping center can significantly influence a user's interest in a house and thereby its price. This lack of contextual information in current models is a key problem that needs to be addressed for more accurate and comprehensive real estate price predictin\n",
    "\n",
    "Another limitation of traditional models is their inability to effectively capture the complex relationships between different neighborhood amenities and house prices. The value of a house is not only determined by its own features but also by the features of its surrounding environment. For example, a house located near a noisy factory may be less desirable than a similar house located near a quiet park. Traditional models often fail to capture these complex relationships, leading to inaccurate predictions. The proposed Geo-Spatial Network Embedding (GSNE) method addresses this limitation by learning the embeddings of houses and various Points of Interest (POIs) in multipartite networks, thereby capturing the complex relationships between houses and their surrounding amenities. This approach significantly improves the performance of the house price prediction task, providing a more comprehensive and accurate model for real estate price prediction.0789-x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a282df-5381-4e88-97e0-4e16c0d981d1",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "Machine learning applications are disrupting the real estate industry by incorporating non-traditional data sources into price prediction models. This approach helps answer questions like: Which house should I buy or build to maximize my return? Where or when should I do so? What is its optimum rent or sale price? By using machine learning algorithms, these models can learn from past data and make accurate predictions about future prices.\n",
    "\n",
    "Another approach involves the use of data mining and machine learning techniques to adjust pricing models and processes, and realize trend estimation that changes over time. This results in a pricing model with advantages such as dynamics, accuracy, and flexibility over the original model. Data mining techniques can uncover hidden patterns and relationships in the data, which can then be used to make more accurate price predictions.\n",
    "\n",
    "Deep learning, a subset of machine learning, can automatically learn complex patterns in the data and make more accurate predictions. This approach overcomes the limitations of traditional methods, which may be prone to human error and may not be able to capture complex patterns in the data. Deep learning models can process a large amount of data and learn from it, improving their accuracy over time.\n",
    "\n",
    "One innovative approach is to calculate and analyze the entropy and information gain of various influencing factors of house prices and extract the main factors affecting real estate prices. This method facilitates the analysis of the relationship between the main factors and establishes a multiple linear regression model according to the relationship between each factor and the real estate price. This approach provides a more scientific and rational basis for real estate price prediction. These solutions leverage advanced technologies and innovative approaches to address the limitations of traditional models, providing more accurate and comprehensive real estate price predictions. They represent the future of real estate price prediction, offering potential benefits for buyers, sellers, and the real estate industry as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da6310-4b94-450c-90f8-8e2788c8c0d3",
   "metadata": {},
   "source": [
    "## The Background of the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f106fd9-add4-44ed-bab2-82178d8a5dd2",
   "metadata": {},
   "source": [
    "| Reference | Explanation | Dataset | Future Improvement |\r\n",
    "|-----------|-------------|---------|--------------------|\r\n",
    "| Basu, S., Thibodeau, T.G.: Analysis of spatial autocorrelation in house prices. The Journal of Real Estate Finance and Economics 17(1), 61–85 (1998) | This paper analyzes the spatial autocorrelation in house prices, which is a crucial factor in real estate price prediction. | Not specified | Future work could explore other factors that might influence spatial autocorrelation in house prices. |\r\n",
    "| Bojchevski, A., G¨unnemann, S.: Deep gaussian embedding of attributed graphs: Unsupervised inductive learning via ranking. arXiv preprint arXiv:1707.03815 (2017) | This paper presents a method for deep Gaussian embedding of attributed graphs, which could be useful for capturing complex relationships in data. | Not specified | Future improvements could include applying this method to other types of data or problems. |\r\n",
    "| Bourassa, S., Cantoni, E., Hoesli, M.: Predicting house prices with spatial dependence: a comparison of alternative methods. Journal of Real Estate Research 32(2), 139–159 (2010) | This paper compares different methods for predicting house prices with spatial dependence, providing valuable insights for real estate price prediction. | Not specified | Future work could involve developing new methods or improving existing ones for predicting house prices with spatial dependence. |\r\n",
    "| Bourassa, S.C., Cantoni, E., Hoesli, M.: Spatial dependence, housing submarkets, and house price prediction. The Journal of Real Estate Finance and Economics 35(2), 143–160 (2007) | This paper discusses the concept of spatial dependence and housing submarkets in the context of house price prediction. | Not specified | Future work could explore the impact of various housing submarkets on spatial dependence and house price prediction. |\r\n",
    "| Bourassa, S.C., Hoesli, M., Peng, V.S.: Do housing submarkets really matter? Journal of Housing Economics 12(1), 12–28 (2003) | This paper investigates the significance of housing submarkets in the real estate industry. | Not specified | Future research could delve deeper into the role and impact of different housing submarkets. |\r\n",
    "| Cai, H., Zheng, V.W., Chang, K.C.C.: A comprehensive survey of graph embedding: Problems, techniques, and applications. IEEE Transactions on Knowledge and Data Engineering 30(9), 1616–1637 (2018) | This paper provides a comprehensive survey of graph embedding, discussing various problems, techniques, and applications. | Not specified | Future work could focus on addressing the problems identified and improving the techniques discussed. |\r\n",
    "| Case, B., Clapp, J., Dubin, R., Rodriguez, M.: Modeling spatial and temporal house price patterns: A comparison of four models. The Journal of Real Estate Finance and Economics 29(2), 167–191 (2004) | This paper compares four models for modeling spatial and temporal house price patterns, contributing to the field of real estate price prediction. | Not specified | Future research could develop new models or improve the existing ones for better prediction of spatial and temporal house price patterns. |\r\n",
    "| Chen, T., Guestrin, C.: Xgboost: A scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pp. 785–794 (2016) | This paper presents XGBoost, a scalable tree boosting system, which could be used for various prediction tasks, including real estate price prediction. | Not specified | Future work could explore the application of XGBoost in different domains and for different prediction tasks. |\r\n",
    "| Chen, X., Wei, L., Xu, J.: House price prediction using lstm. arXiv preprint arXiv:1709.08432 (2017) | This paper discusses the use of Long Short-Term Memory (LSTM) for house price prediction. | Not specified | Future research could focus on improving the LSTM model for better house price prediction. |\r\n",
    "| Clevert, D.A., Unterthiner, T., Hochreiter, S.: Fast and accurate deep network learning by exponential linear units (ELUs). arXiv preprint arXiv:1511.07289 (2015) | This paper presents a method for fast and accurate deep network learning using Exponential Linear Units (ELUs), which could be applied to various learning tasks, including real estate price prediction. | Not specified | Future work could focus on improving the ELU-based deep learning method for better performance. |\r\n",
    "| Dubin, R.A.: Predicting house prices using multiple listings data. The Journal of Real Estate Finance and Economics 17(1), 35–59 (1998) | This paper discusses the use of multiple listings data for predicting house prices, providing a new perspective in the field of real estate price prediction. | Not specified | Future research could explore other types of data for house price prediction. |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6083e3e-01f7-4163-a1e1-cbb9bd3bdd97",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "To implement the gradient boosting framework on both categorical and numerical data, here XGBoost is used for the implementation of the concept. This approach allows us to leverage the power of XGBoost's speed and performance for efficient and effective real estate price prediction. It handles both categorical and numerical features, making it a versatile tool for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7a846-31f4-4886-8cef-667d805085db",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost, short for eXtreme Gradient Boosting, is a powerful machine learning algorithm widely used in the field of data science and machine learning. It's an implementation of gradient-boosting machines, designed to be highly efficient, flexible, and portable. \r\n",
    "In the context of house price prediction, XGBoost can be particularly useful due to its ability to handle a variety of data types, including both categorical and numerical data, and its capability to model complex non-linear relationships. It works by building an ensemble of decision trees in a sequential manner, where each new tree is built to correct the errors made by the existing ensembl T\n",
    "\r\n",
    "The algorithm also includes several regularization parameters to prevent overfitting, making it robust to noise and outliers in the data. This makes XGBoost a great choice for building a house price prediction model, as it can effectively capture the intricate patterns in the data and provide accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81310d62-90c2-4bdc-a4df-137fa9066768",
   "metadata": {},
   "source": [
    "## Insights and Execution\n",
    "\n",
    "\r\n",
    "**Detailed Insights**\r\n",
    "The current version includes the following steps:\r\n",
    "\r\n",
    "- **Loading Datasets**: Importing datasets in CSV or other formats that contain historical house prices and related features.\r\n",
    "\r\n",
    "- **Preprocessing of Data**: Cleaning the data, handling missing values, outliers, and performing exploratory data analysis. This step also involves feature engineering where new features are created from the existing data that might help improve the performance of the prediction model.\r\n",
    "\r\n",
    "- **Model Training**: Training the XGBoost model using a subset of the collected data. This involves feeding the data into the model so it can learn the relationships between the features and the target variable (house prices).\r\n",
    "\r\n",
    "- **Model Evaluation**: Evaluating the performance of the model using appropriate metrics, such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), or R-squared. This helps us understand how well our model is performing.\r\n",
    "\r\n",
    "- **Hyperparameter Tuning**: Tuning the hyperparameters of the XGBoost model to improve its performance. This could involve techniques like Grid Search or Random Search.\r\n",
    "\r\n",
    "- **Prediction**: Using the trained model to predict house prices for new data. This is where we can see the results of our work and use it for practical applications.\r\n",
    "\r\n",
    "- **Feature Importance Analysis**: Analyzing the feature importance scores provided by XGBoost to understand which features are most influential in predicting house prices.\r\n",
    "\r\n",
    "- **Model Deployment (Optional)**: Deploying the model in a suitable environment where it can be used to make predictions in real-time. This could be a local server, cloud platform, or even embedded in a mobile or web application.\r\n",
    "\r\n",
    "- **Monitoring and Updating (Optional)**: Continuously monitoring the model's performance over time and updating or retraining it as necessary. This ensures that the model remains effective as new data comes in.in a mobile or.new data comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9174c-41fe-4f2c-b8b6-466747aa5f59",
   "metadata": {},
   "source": [
    "#### Reference: https://arxiv.org/pdf/2009.00254v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c8998",
   "metadata": {},
   "source": [
    "# # Exploratory Data Analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769f9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                           # Importing Numpy important python library \n",
    "import pandas as pd                         # Importing Pandas library for EDA Purpose\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns                      # Importing Seaborn for Ploting graphs.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2810a65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Offers</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1790</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>East</td>\n",
       "      <td>114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>East</td>\n",
       "      <td>114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1740</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>East</td>\n",
       "      <td>114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>East</td>\n",
       "      <td>94700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2130</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>East</td>\n",
       "      <td>119800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home  SqFt  Bedrooms  Bathrooms  Offers Neighborhood   Price\n",
       "0     1  1790         2          2       2         East  114300\n",
       "1     2  2030         4          2       3         East  114200\n",
       "2     3  1740         3          2       1         East  114800\n",
       "3     4  1980         3          2       3         East   94700\n",
       "4     5  2130         3          3       3         East  119800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_ori.csv\")    # Fetching Dataset using python Library.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a668833",
   "metadata": {},
   "source": [
    "## # ----} Boosting Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dc19793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16f232a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST Params: {}\\n'.format(results.best_params_))\n",
    "    \n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    \n",
    "    for mean,std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e484a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 4}\n",
      "\n",
      "0.687 (+/-0.326) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 2}\n",
      "0.694 (+/-0.302) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 4}\n",
      "0.701 (+/-0.32) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 6}\n",
      "0.711 (+/-0.303) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 12}\n",
      "0.706 (+/-0.297) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 2}\n",
      "0.72 (+/-0.31) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 4}\n",
      "0.718 (+/-0.287) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 6}\n",
      "0.715 (+/-0.307) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 12}\n",
      "0.718 (+/-0.287) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 2}\n",
      "0.72 (+/-0.312) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 4}\n",
      "0.704 (+/-0.26) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 6}\n",
      "0.706 (+/-0.297) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 12}\n",
      "0.72 (+/-0.299) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 2}\n",
      "0.718 (+/-0.288) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 4}\n",
      "0.701 (+/-0.294) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 6}\n",
      "0.715 (+/-0.293) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 12}\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [2, 4, 6, 12],\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de36857f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=7, n_estimators=4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_                                           # Stores best estimated outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68190bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB_model.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'GB_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1de3b4",
   "metadata": {},
   "source": [
    "# # Analyzing the results on Test Dataset, in order to do validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f82880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Offers</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1930</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1678</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2903</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>832</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8732</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home   SqFt  Bedrooms  Bathrooms  Offers  Neighborhood   Price\n",
       "0      1  1930         4          2       3             2  100000\n",
       "1      2  1678         5          5       4             0  120000\n",
       "2      3  2903         6          3       2             2   80000\n",
       "3      4   832         3          2       1             1   76000\n",
       "4      5  8732         2          1       1             2  135000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "891b4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = test.iloc[:, :-1]\n",
    "Y = test.iloc[:, -1]\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b96590",
   "metadata": {},
   "source": [
    "### ---} Types Of Models & Their Best Result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b5d7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for mdl in ['LR', 'MLP', 'SVM', 'RF', 'GB']:\n",
    "    models[mdl] = joblib.load('{}_model.pkl'.format(mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "344dba43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=10),\n",
       " 'MLP': MLPClassifier(activation='tanh', hidden_layer_sizes=(10,)),\n",
       " 'SVM': SVC(C=10, kernel='linear'),\n",
       " 'RF': RandomForestClassifier(max_depth=32, n_estimators=250),\n",
       " 'GB': GradientBoostingClassifier(max_depth=7, n_estimators=4)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6ee92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, x, y):\n",
    "    start = time()\n",
    "    pred = model.predict(x)\n",
    "    end = time()\n",
    "    \n",
    "    accuracy = round(accuracy_score(y, pred), 3)\n",
    "    precision = round(precision_score(y, pred, average = 'weighted'), 3)\n",
    "    recall = round(recall_score(y, pred, average = 'weighted'), 3)\n",
    "    \n",
    "    print('{} -- Accuracy: {} / precision: {} / Recall: {} / Latency: {}ms'.format(name, accuracy, precision, recall, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a841855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- Accuracy: 0.038 / precision: 0.006 / Recall: 0.038 / Latency: 0.0ms\n",
      "MLP -- Accuracy: 0.024 / precision: 0.002 / Recall: 0.024 / Latency: 0.0ms\n",
      "SVM -- Accuracy: 0.984 / precision: 0.986 / Recall: 0.984 / Latency: 0.04174470901489258ms\n",
      "RF -- Accuracy: 1.0 / precision: 1.0 / Recall: 1.0 / Latency: 0.03621721267700195ms\n",
      "GB -- Accuracy: 1.0 / precision: 1.0 / Recall: 1.0 / Latency: 0.0ms\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, x_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e2d2b-d07a-4107-908d-5d1b0e188081",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Upon successful execution of the house price prediction project, we can conclude that machine learning provides a powerful tool for predicting house prices based on a variety of features. The insights gained from the feature importance can provide valuable information for home buyers, sellers, and real estate professionals, helping them make informed decisions. Furthermore, the project demonstrates the potential of machine learning in transforming the real estate industry by providing more accurate and reliable house price predictions. This could lead to more efficient markets, better investment decisions, and ultimately, a more robust real estate sector. The project also highlights the importance of continuous model monitoring and updating to ensure the model remains effective as new data comes in, reflecting the dynamic nature of the real estate market. In addition, the project underscores the importance of data quality and preprocessing in achieving accurate predictions. It shows that careful handling of missing values, outliers, and proper feature engineering can significantly improve the model's performance. The project also highlights the potential of machine learning models to uncover hidden patterns and relationships in the data that might not be apparent through traditional analysis methods. Lastly, the project emphasizes the role of continuous learning and adaptation in machine learning models to keep up with the ever-changing dynamics of real estate markets. This adaptability is crucial in ensuring the long-term effectiveness and relevance of the model in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faa946-d4d8-4d0d-88fd-4713f7d01e8f",
   "metadata": {},
   "source": [
    "## Future Scope\n",
    "\n",
    "The future directions for a house price prediction project could involve several avenues. One potential direction is the integration of more diverse data sources. While the current model may rely on traditional data sources such as property size, location, and nearby amenities, future models could incorporate more unconventional data. This could include data related to local economic indicators, demographic trends, or even social media sentiment. Incorporating these types of data could help capture the broader societal trends that influence house prices and improve the accuracy of the model.\n",
    "\n",
    "Another promising direction is the exploration of more advanced machine learning techniques. While the current project uses XGBoost, future work could explore the use of deep learning techniques, which have shown promise in handling complex, high-dimensional data. For instance, convolutional neural networks (CNNs) could be used to analyze images of properties, while recurrent neural networks (RNNs) or transformers could be used to analyze temporal trends in house prices. These techniques could provide more nuanced and accurate predictions, further advancing the field of real estate price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8e71f-961e-449d-bf01-39d77239c88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
